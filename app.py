import streamlit as st
import google.generativeai as genai
import time
from PIL import Image

# --- 1. í˜ì´ì§€ ë° ë””ìì¸ ì„¤ì • ---
st.set_page_config(page_title="Leisure DNA: Premium Curator", layout="wide", page_icon="ğŸ§¬")

st.markdown("""
    <style>
    /* ì „ì²´ ë°°ê²½: ì›œ ê·¸ë ˆì´ */
    .stApp { background-color: #F5F5F7; }
    
    /* í—¤ë” ìŠ¤íƒ€ì¼: ë”¥ ë„¤ì´ë¹„ */
    h1 { 
        color: #1D1D1F; 
        font-family: 'Helvetica Neue', sans-serif; 
        font-weight: 800; 
        letter-spacing: -1px;
        padding-bottom: 20px;
        border-bottom: 2px solid #E5E5EA;
    }
    
    /* ì±„íŒ…ì°½ ë””ìì¸ ê°œì„  */
    .stChatMessage { 
        border-radius: 20px; 
        padding: 15px; 
        box-shadow: 0 4px 10px rgba(0,0,0,0.05);
    }
    div[data-testid="stChatMessage"]:nth-child(even) {
        background-color: #ffffff; 
        border: 1px solid #E5E5EA;
    }
    div[data-testid="stChatMessage"]:nth-child(odd) {
        background-color: #E8F0FE; 
        border: none;
        color: #1A73E8;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Google Gemini API ì„¤ì • ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("ğŸš¨ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
except Exception as e:
    st.error(f"âš ï¸ API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# --- 3. í˜ë¥´ì†Œë‚˜ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸) ---
SYSTEM_INSTRUCTION = """
ë‹¹ì‹ ì€ 'AI í”„ë¦¬ë¯¸ì—„ ë¼ì´í”„ìŠ¤íƒ€ì¼ íë ˆì´í„°'ì…ë‹ˆë‹¤.
ê¸°ê³„ì ì¸ ì±—ë´‡ì´ ì•„ë‹Œ, **ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ê°€ ìˆ˜ì¤€ì˜ ê³µê° ëŠ¥ë ¥**ê³¼ **ìœ ì—°í•œ ëŒ€í™” ìŠ¤í‚¬**ì„ ê°–ì¶”ì‹­ì‹œì˜¤.

[ëŒ€í™” ì›ì¹™]
1. ì²« ì¸ì‚¬ëŠ” ì‚¬ìš©ìì˜ ìƒí™©(ì‹œê°„, ë‚ ì”¨ ë“±)ì— ë§ì¶° ë”°ëœ»í•˜ê²Œ ê±´ë„¤ì‹­ì‹œì˜¤. ("ì•ˆë…•í•˜ì„¸ìš”" ê¸ˆì§€ -> "í–‡ì‚´ì´ ì¢‹ì€ ì˜¤í›„ë„¤ìš”" ë“±)
2. ì§ˆë¬¸ì€ í•œ ë²ˆì— í•˜ë‚˜ë§Œ í•˜ì‹­ì‹œì˜¤. (ì •ë³´ ìˆ˜ì§‘ ìˆœì„œ: ê¸°ë¶„/ìƒíƒœ -> ë™ë°˜ì -> ìŠ¤íƒ€ì¼ -> ì˜ˆì‚°)
3. ì‚¬ìš©ìì˜ ë‹µë³€ì— ê¹Šì´ ê³µê°í•œ ë’¤ ë‹¤ìŒ ì§ˆë¬¸ì„ í•˜ì‹­ì‹œì˜¤.
4. êµ¬ê¸€ ë§µ í‰ì  4.5 ì´ìƒì˜ ì‹¤ì¡´ ì¥ì†Œë§Œ ì¶”ì²œí•˜ì‹­ì‹œì˜¤.

ì§€ê¸ˆ ë‹¹ì¥ ì²« ì¸ì‚¬ë¥¼ ê±´ë„¤ë©° ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì‹­ì‹œì˜¤.
"""

# --- 4. ì„¸ì…˜ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 5. ëª¨ë¸ ì´ˆê¸°í™” (ì—ëŸ¬ ë°©ì§€ ë¡œì§ í¬í•¨) ---
if "chat_session" not in st.session_state:
    try:
        # ëª¨ë¸ì„ ê°€ì¥ ì•ˆì •ì ì¸ 'gemini-1.5-flash'ë¡œ ì„¤ì •
        model = genai.GenerativeModel(
            model_name="gemini-1.5-flash", 
            system_instruction=SYSTEM_INSTRUCTION
        )
        st.session_state.chat_session = model.start_chat(history=[])
        
        # ì²« ì¸ì‚¬ ìƒì„±
        response = st.session_state.chat_session.send_message("ì²« ì¸ì‚¬ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
        st.session_state.messages.append({"role": "assistant", "content": response.text})
        
    except Exception as e:
        st.error(f"âŒ AI ì—°ê²° ì‹¤íŒ¨: {e}")
        st.info("ğŸ’¡ íŒ: API Keyê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ê±°ë‚˜, ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

# --- 6. UI êµ¬ì„± ---
st.title("ğŸ›ï¸ Lifestyle Curator")
st.caption("ê³µê°„ ì‚¬ì§„ì„ ì˜¬ë¦¬ê±°ë‚˜, ëŒ€í™”ë¥¼ í†µí•´ ë‹¹ì‹ ë§Œì˜ íœ´ì‹ì„ ì„¤ê³„í•´ ë“œë¦½ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” (ì‚¬ì§„ ì—…ë¡œë“œ)
with st.sidebar:
    st.header("ğŸ“¸ Space Analysis")
    uploaded_file = st.file_uploader("ê³µê°„ ì‚¬ì§„ ë¶„ì„", type=["jpg", "png", "jpeg"])
    user_image = None
    if uploaded_file:
        user_image = Image.open(uploaded_file)
        st.image(user_image, caption="ì´ë¯¸ì§€ ë¡œë“œë¨", use_container_width=True)

# ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì…ë ¥ì°½
if prompt := st.chat_input("ëŒ€í™”ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        try:
            # ì´ë¯¸ì§€ ìˆìœ¼ë©´ ê°™ì´ ì „ì†¡
            if user_image:
                response = st.session_state.chat_session.send_message([prompt, user_image])
            else:
                response = st.session_state.chat_session.send_message(prompt)
                
            # íƒ€ì´í•‘ íš¨ê³¼
            full_response = response.text
            for chunk in full_response.split():
                display_text = full_response[:full_response.find(chunk)+len(chunk)]
                message_placeholder.markdown(full_response + "â–Œ") 
                time.sleep(0.02)
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"ëŒ€í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.session_state.messages.append({"role": "assistant", "content": " ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."})
